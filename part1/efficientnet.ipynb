{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.datasets import load_files   \n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from glob import glob\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "class_names = sorted(os.listdir(r\"/home/nvme/data/train/train\"))\n",
    "\n",
    "N_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.5125 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5375 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "import efficientnet.tfkeras as efn \n",
    "\n",
    "base_model = efn.EfficientNetB6(weights='imagenet', include_top = False, input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "#x = Dense(4096, activation='relu')(x)\n",
    "# and a logistic layer \n",
    "predictions = Dense(N_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "adam = Adam(lr = 0.0001)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22443 images belonging to 17 classes.\n",
      "Found 5602 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# example of progressively loading images from file\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create generator\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #rotation_range=20,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    rescale = 1./255.,\n",
    "    #horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_gen = datagen.flow_from_directory('/home/nvme/data/train/train',\n",
    "                                        class_mode = \"categorical\",\n",
    "                                        target_size = (224, 224),\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = True,\n",
    "                                        subset = \"training\",\n",
    "                                        seed = 42)\n",
    "val_gen = datagen.flow_from_directory('/home/nvme/data/train/train',\n",
    "                                        class_mode = \"categorical\",\n",
    "                                        target_size = (224, 224),\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = True,\n",
    "                                        subset = \"validation\",\n",
    "                                        seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Large dropout rate: 0.5125 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5375 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "  18/1402 [..............................] - ETA: 19:58 - loss: 2.7495 - accuracy: 0.1042"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "    steps_per_epoch = train_gen.samples // batch_size,\n",
    "    validation_data = val_gen, \n",
    "    validation_steps = val_gen.samples // batch_size,\n",
    "    epochs = epochs \n",
    "    #,callbacks=[tensorboard_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:658]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[658:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.00001, momentum=0.9),\n",
    "                            loss='categorical_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "    steps_per_epoch = train_gen.samples // batch_size,\n",
    "    validation_data = val_gen, \n",
    "    validation_steps = val_gen.samples // batch_size,\n",
    "    epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "test_gen = datagen_test.flow_from_directory('/home/nvme/data/test',\n",
    "                                        #class_mode = \"categorical\",\n",
    "                                        target_size = (224, 224),\n",
    "                                        batch_size = 1,\n",
    "                                        shuffle = False)\n",
    "\n",
    "pred = model.predict_generator(test_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p = np.argmax(pred, axis = 1)\n",
    "predictions = [class_names[k] for k in p]\n",
    "a = np.arange(len(predictions))\n",
    "d = {'Id': a, 'Category': predictions}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df.to_csv(\"submission2.csv\", index = None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

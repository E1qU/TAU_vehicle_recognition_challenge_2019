{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.datasets import load_files   \n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from glob import glob\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "class_names = sorted(os.listdir(r\"/home/nvme/data/train/train\"))\n",
    "\n",
    "N_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    weights = \"imagenet\",\n",
    "    input_shape = (224,224,3),\n",
    "    include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(N_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "adam = Adam(lr = 0.0001)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22443 images belonging to 17 classes.\n",
      "Found 5602 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# example of progressively loading images from file\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create generator\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #rotation_range=20,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    rescale = 1./255.,\n",
    "    #horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_directory('/home/nvme/data/train/train',\n",
    "                                        class_mode = \"categorical\",\n",
    "                                        target_size = (224, 224),\n",
    "                                        batch_size = 32,\n",
    "                                        shuffle = True,\n",
    "                                        subset = \"training\",\n",
    "                                        seed = 42)\n",
    "val_gen = datagen.flow_from_directory('/home/nvme/data/train/train',\n",
    "                                        class_mode = \"categorical\",\n",
    "                                        target_size = (224, 224),\n",
    "                                        batch_size = 32,\n",
    "                                        shuffle = True,\n",
    "                                        subset = \"validation\",\n",
    "                                        seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "701/701 [==============================] - 858s 1s/step - loss: 0.7906 - accuracy: 0.7608 - val_loss: 0.7074 - val_accuracy: 0.8141\n",
      "Epoch 2/10\n",
      "701/701 [==============================] - 861s 1s/step - loss: 0.6019 - accuracy: 0.8049 - val_loss: 0.7070 - val_accuracy: 0.8227\n",
      "Epoch 3/10\n",
      "701/701 [==============================] - 872s 1s/step - loss: 0.5519 - accuracy: 0.8219 - val_loss: 0.6185 - val_accuracy: 0.8411\n",
      "Epoch 4/10\n",
      "701/701 [==============================] - 864s 1s/step - loss: 0.5185 - accuracy: 0.8295 - val_loss: 0.7316 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "701/701 [==============================] - 865s 1s/step - loss: 0.4944 - accuracy: 0.8350 - val_loss: 0.7293 - val_accuracy: 0.8011\n",
      "Epoch 6/10\n",
      "701/701 [==============================] - 872s 1s/step - loss: 0.4796 - accuracy: 0.8429 - val_loss: 0.6553 - val_accuracy: 0.8398\n",
      "Epoch 7/10\n",
      "701/701 [==============================] - 858s 1s/step - loss: 0.4555 - accuracy: 0.8442 - val_loss: 0.6929 - val_accuracy: 0.8316\n",
      "Epoch 8/10\n",
      "701/701 [==============================] - 858s 1s/step - loss: 0.4212 - accuracy: 0.8563 - val_loss: 0.6777 - val_accuracy: 0.8382\n",
      "Epoch 9/10\n",
      "701/701 [==============================] - 857s 1s/step - loss: 0.4024 - accuracy: 0.8636 - val_loss: 0.6660 - val_accuracy: 0.8289\n",
      "Epoch 10/10\n",
      "100/701 [===>..........................] - ETA: 8:58 - loss: 0.3625 - accuracy: 0.8731"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "    steps_per_epoch = train_gen.samples // 32,\n",
    "    validation_data = val_gen, \n",
    "    validation_steps = val_gen.samples // 32,\n",
    "    epochs = epochs \n",
    "    #,callbacks=[tensorboard_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.00001, momentum=0.9),\n",
    "                            loss='categorical_crossentropy',\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "    steps_per_epoch = train_gen.samples // 32,\n",
    "    validation_data = val_gen, \n",
    "    validation_steps = val_gen.samples // 32,\n",
    "    epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "test_gen = datagen_test.flow_from_directory('/home/nvme/data/test',\n",
    "                                        #class_mode = \"categorical\",\n",
    "                                        target_size = (224, 224),\n",
    "                                        batch_size = 1,\n",
    "                                        shuffle = False)\n",
    "\n",
    "pred = model.predict_generator(test_gen, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p = np.argmax(pred, axis = 1)\n",
    "predictions = [class_names[k] for k in p]\n",
    "a = np.arange(len(predictions))\n",
    "d = {'Id': a, 'Category': predictions}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df.to_csv(\"submission2.csv\", index = None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
